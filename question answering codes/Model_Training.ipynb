{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Word embedding\ninference\n","metadata":{"id":"RTlfR0tU_cxi"}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:31:11.113934Z","iopub.execute_input":"2022-04-04T05:31:11.114383Z","iopub.status.idle":"2022-04-04T05:31:12.540386Z","shell.execute_reply.started":"2022-04-04T05:31:11.114345Z","shell.execute_reply":"2022-04-04T05:31:12.539643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"id":"zIb_bYEXIL3d","outputId":"7b9f735f-dc8d-4722-b6c0-c62b13129387","execution":{"iopub.status.busy":"2022-04-04T05:31:12.542126Z","iopub.execute_input":"2022-04-04T05:31:12.542387Z","iopub.status.idle":"2022-04-04T05:31:21.600915Z","shell.execute_reply.started":"2022-04-04T05:31:12.542353Z","shell.execute_reply":"2022-04-04T05:31:21.60017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:31:21.602093Z","iopub.execute_input":"2022-04-04T05:31:21.602517Z","iopub.status.idle":"2022-04-04T05:31:31.202031Z","shell.execute_reply.started":"2022-04-04T05:31:21.602477Z","shell.execute_reply":"2022-04-04T05:31:31.201231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'bert-base-uncased'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:31:31.204117Z","iopub.execute_input":"2022-04-04T05:31:31.204369Z","iopub.status.idle":"2022-04-04T05:31:31.211162Z","shell.execute_reply.started":"2022-04-04T05:31:31.204336Z","shell.execute_reply":"2022-04-04T05:31:31.210401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\nprint(\"bert model is now available\")\nmodel = BertModel.from_pretrained(MODEL_NAME)\nmodel = model.to(torch.device('cpu'))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:31:31.212466Z","iopub.execute_input":"2022-04-04T05:31:31.212942Z","iopub.status.idle":"2022-04-04T05:31:47.921905Z","shell.execute_reply.started":"2022-04-04T05:31:31.212902Z","shell.execute_reply":"2022-04-04T05:31:47.921057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input:Text Sentence, Output:BERT Representation of the sentence\ndef get_bert_embeddings(text):\n\n    '''\n    1.  Use the BERT tokenizer to first split the word into tokens\n    2.  Add the special tokens needed for sentence classifications (these are [CLS] at the first position, and [SEP] at the end of the sentence).\n    3.  Replace each token with its id from the embedding table which is a component we get with the trained model.\n    '''\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    outputs = model(**inputs,output_hidden_states=True)\n    hidden_states = outputs.hidden_states\n    token_vecs = torch.cat((hidden_states[-4], torch.cat((hidden_states[-3], torch.cat(\n        (hidden_states[-2], hidden_states[-1]), dim=0)), dim=0)), dim=0)\n    vectors = torch.mean(torch.mean(token_vecs, dim=0), dim=0)\n#     return inputs\n    return vectors\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:33:19.908788Z","iopub.execute_input":"2022-04-04T05:33:19.909559Z","iopub.status.idle":"2022-04-04T05:33:19.916446Z","shell.execute_reply.started":"2022-04-04T05:33:19.909518Z","shell.execute_reply":"2022-04-04T05:33:19.915373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_ids_to_tokens(get_bert_embeddings(\"It is running to see you. I like cats.\")['input_ids'][0])[1:-1]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:33:22.6239Z","iopub.execute_input":"2022-04-04T05:33:22.624642Z","iopub.status.idle":"2022-04-04T05:33:22.849747Z","shell.execute_reply.started":"2022-04-04T05:33:22.624591Z","shell.execute_reply":"2022-04-04T05:33:22.848927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_bert_embeddings(\"It is running to see you.\")['input_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:31:48.601105Z","iopub.status.idle":"2022-04-04T05:31:48.602065Z","shell.execute_reply.started":"2022-04-04T05:31:48.601776Z","shell.execute_reply":"2022-04-04T05:31:48.601807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass Attention(tf.keras.layers.Layer):\n\n    def __init__(self, return_sequences=True, name=None, **kwargs):\n        super(Attention, self).__init__(name=name)\n        self.return_sequences = return_sequences\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n    \n        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n                           initializer=\"glorot_uniform\", trainable=True)\n        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n                           initializer=\"glorot_uniform\", trainable=True)\n    \n        super(Attention, self).build(input_shape)\n\n    def call(self, x):\n    \n        e = tf.keras.activations.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n        a = tf.keras.activations.softmax(e, axis=1)\n        output = x * a\n    \n        if self.return_sequences:\n            return a, output\n    \n        return a, tf.keras.backend.sum(output, axis=1)\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'return_sequences': self.return_sequences \n        })\n        return config","metadata":{"id":"-LKC41cIrAOG","execution":{"iopub.status.busy":"2022-04-01T20:59:59.573912Z","iopub.execute_input":"2022-04-01T20:59:59.574129Z","iopub.status.idle":"2022-04-01T20:59:59.586238Z","shell.execute_reply.started":"2022-04-01T20:59:59.574102Z","shell.execute_reply":"2022-04-01T20:59:59.585225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nimport numpy as np\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model\nfrom keras.layers import Concatenate, LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy\n# # Path to translation file\n# path_to_data = 'data/spa.txt'\n\n# # Read file\n# translation_file = open(path_to_data,\"r\", encoding='utf-8') \n# raw_data = translation_file.read()\n# translation_file.close()\n\n# # Parse data\n# raw_data = raw_data.split('\\n')\n# pairs = [sentence.split('\\t') for sentence in  raw_data]\n# pairs = pairs[1000:20000]","metadata":{"id":"_GrpACeP08Zw","outputId":"b4ee8c8e-2a43-4aac-f177-7985b94415c0","execution":{"iopub.status.busy":"2022-04-03T07:41:47.968584Z","iopub.execute_input":"2022-04-03T07:41:47.968854Z","iopub.status.idle":"2022-04-03T07:41:48.860319Z","shell.execute_reply.started":"2022-04-03T07:41:47.968825Z","shell.execute_reply":"2022-04-03T07:41:48.859574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocess data","metadata":{"id":"3lHQ93PVEV2D"}},{"cell_type":"code","source":"input_train_path=\"../input/squad-text/input_train.txt\"\noutput_train_path=\"../input/squad-text/output_train.txt\"\ninput_dev_path=\"../input/squad-text/input_dev.txt\"\noutput_dev_path=\"../input/squad-text/output_dev.txt\"\n\ninput_ques_train_path=\"../input/squad-text/input_ques_train.txt\"\ninput_context_train_path=\"../input/squad-text/input_context_train.txt\"\noutput_train_path=\"../input/squad-text/output_train.txt\"\ninput_ques_dev_path=\"../input/squad-text/input_ques_dev.txt\"\ninput_context_dev_path=\"../input/squad-text/input_context_dev.txt\"\noutput_dev_path=\"../input/squad-text/output_dev.txt\"\n\n\ninput_train_file = open(input_train_path,\"r\", encoding='utf-8')\ninput_train_data = input_train_file.read()\ninput_train_file.close()\n\noutput_train_file = open(output_train_path,\"r\", encoding='utf-8')\noutput_train_data = output_train_file.read()\noutput_train_file.close()\n\ninput_dev_file = open(input_dev_path,\"r\", encoding='utf-8')\ninput_dev_data = input_dev_file.read()\ninput_dev_file.close()\n\noutput_dev_file = open(output_dev_path,\"r\", encoding='utf-8')\noutput_dev_data = output_dev_file.read()\noutput_dev_file.close()\n\n####\ninput_ques_train_file = open(input_ques_train_path,\"r\", encoding='utf-8')\ninput_ques_train_data = input_ques_train_file.read()\ninput_ques_train_file.close()\n\ninput_context_train_file = open(input_context_train_path,\"r\", encoding='utf-8')\ninput_context_train_data = input_context_train_file.read()\ninput_context_train_file.close()\n\ninput_ques_dev_file = open(input_ques_dev_path,\"r\", encoding='utf-8')\ninput_ques_dev_data = input_ques_dev_file.read()\ninput_ques_dev_file.close()\n\ninput_context_dev_file = open(input_context_dev_path,\"r\", encoding='utf-8')\ninput_context_dev_data = input_context_dev_file.read()\ninput_context_dev_file.close()\n\noutput_train_file = open(output_train_path,\"r\", encoding='utf-8')\noutput_train_data = output_train_file.read()\noutput_train_file.close()\n\noutput_dev_file = open(output_dev_path,\"r\", encoding='utf-8')\noutput_dev_data = output_dev_file.read()\noutput_dev_file.close()","metadata":{"id":"uzsbxxhz3Zik","execution":{"iopub.status.busy":"2022-04-03T07:45:02.437801Z","iopub.execute_input":"2022-04-03T07:45:02.438144Z","iopub.status.idle":"2022-04-03T07:45:03.607528Z","shell.execute_reply.started":"2022-04-03T07:45:02.438109Z","shell.execute_reply":"2022-04-03T07:45:03.606737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parse data\ninput_train_data = input_train_data.split('\\n')\noutput_train_data = output_train_data.split('\\n')\ninput_dev_data = input_dev_data.split('\\n')\noutput_dev_data = output_dev_data.split('\\n')\n\n##\n\ninput_ques_train_data = input_ques_train_data.split('\\n')\ninput_ques_dev_data = input_ques_dev_data.split('\\n')\ninput_context_train_data = input_context_train_data.split('\\n')\ninput_context_dev_data = input_context_dev_data.split('\\n')\n# output_train_data = output_train_data.split('\\n')\n# output_dev_data = output_dev_data.split('\\n')","metadata":{"id":"CBZEKly86nTN","execution":{"iopub.status.busy":"2022-04-03T07:46:14.511905Z","iopub.execute_input":"2022-04-03T07:46:14.512389Z","iopub.status.idle":"2022-04-03T07:46:14.609551Z","shell.execute_reply.started":"2022-04-03T07:46:14.512355Z","shell.execute_reply":"2022-04-03T07:46:14.608826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_sentence(sentence):\n    # Lower case the sentence\n    lower_case_sent = sentence.lower()\n    # Strip punctuation\n    string_punctuation = string.punctuation + \"¡\" + '¿'\n    clean_sentence = lower_case_sent.translate(str.maketrans('', '', string_punctuation))\n   \n    return clean_sentence","metadata":{"id":"3T7-tGg-5rT_","execution":{"iopub.status.busy":"2022-04-01T20:59:59.908597Z","iopub.execute_input":"2022-04-01T20:59:59.908942Z","iopub.status.idle":"2022-04-01T20:59:59.914791Z","shell.execute_reply.started":"2022-04-01T20:59:59.908903Z","shell.execute_reply":"2022-04-01T20:59:59.91394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(sentences):\n    # Create tokenizer\n    text_tokenizer = Tokenizer()\n    # Fit texts\n    text_tokenizer.fit_on_texts(sentences)\n    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer","metadata":{"id":"QvrmdnKa5UzW","execution":{"iopub.status.busy":"2022-04-01T20:59:59.919097Z","iopub.execute_input":"2022-04-01T20:59:59.919751Z","iopub.status.idle":"2022-04-01T20:59:59.924779Z","shell.execute_reply.started":"2022-04-01T20:59:59.919711Z","shell.execute_reply":"2022-04-01T20:59:59.924013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# of Train Sentences: \",len(output_train_data))\nprint(\"# of Dev Sentences: \",len(output_dev_data))","metadata":{"id":"Pv_D2ZRP8U7P","outputId":"c4f0c619-0360-4b58-de8c-7aac60e0112a","execution":{"iopub.status.busy":"2022-04-01T20:59:59.926208Z","iopub.execute_input":"2022-04-01T20:59:59.926693Z","iopub.status.idle":"2022-04-01T20:59:59.934729Z","shell.execute_reply.started":"2022-04-01T20:59:59.926655Z","shell.execute_reply":"2022-04-01T20:59:59.933773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Seperate VOCAB\n#Combine train an dev\ninput_data=input_train_data+input_dev_data\noutput_data=output_train_data+output_dev_data\n\n# Clean sentences\ninput = [clean_sentence(input) for input in input_data]\noutput = [clean_sentence(output) for output in output_data]\n\n# Tokenize words\ninput_tokenized, input_tokenizer = tokenize(input)\noutput_tokenized, output_tokenizer = tokenize(output)\n\nprint('Maximum length input sentence: {}'.format(len(max(input_tokenized,key=len))))\nprint('Maximum length output sentence: {}'.format(len(max(output_tokenized,key=len))))\n\n\n# Check language length\ninput_vocab = len(input_tokenizer.word_index) + 1\noutput_vocab = len(output_tokenizer.word_index) + 1\nprint(\"Input vocabulary is of {} unique words\".format(input_vocab))\nprint(\"Output vocabulary is of {} unique words\".format(output_vocab))\n\n# ## Combined Vocab\n# #Combine train an dev\n# all_data=input_data+output_data\n\n# # Clean sentences\n# all = [clean_sentence(data) for data in all_data]\n\n# # Tokenize words\n# all_tokenized, all_tokenizer = tokenize(all)\n\n# print('Maximum length of sentence: {}'.format(len(max(all_tokenized,key=len))))\n\n\n# # Check language length\n# vocab = len(all_tokenizer.word_index) + 1\n# print(\"Vocabulary is of {} unique words\".format(vocab))\n","metadata":{"id":"UTaRUvq66aRO","outputId":"8d9f8b80-f939-45c4-ec8c-3d71415cf23a","execution":{"iopub.status.busy":"2022-04-01T20:59:59.936322Z","iopub.execute_input":"2022-04-01T20:59:59.937003Z","iopub.status.idle":"2022-04-01T21:00:10.520872Z","shell.execute_reply.started":"2022-04-01T20:59:59.936964Z","shell.execute_reply":"2022-04-01T21:00:10.520071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ques Input","metadata":{}},{"cell_type":"code","source":"# input_tokenizer.texts_to_sequences()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:10.5222Z","iopub.execute_input":"2022-04-01T21:00:10.52252Z","iopub.status.idle":"2022-04-01T21:00:10.527366Z","shell.execute_reply.started":"2022-04-01T21:00:10.522473Z","shell.execute_reply":"2022-04-01T21:00:10.526254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Seperate VOCAB\n#Combine train an dev\ninput_ques_data=input_ques_train_data+input_ques_dev_data\ninput_context_data=input_ques_train_data+input_context_dev_data\noutput_data=output_train_data+output_dev_data\n\n# Clean sentences\ninput_ques = [clean_sentence(input) for input in input_ques_data]\ninput_context = [clean_sentence(input) for input in input_context_data]\noutput = [clean_sentence(output) for output in output_data]\n\n# Tokenize words\ninput_ques_tokenized = input_tokenizer.texts_to_sequences(input_ques)\ninput_context_tokenized = input_tokenizer.texts_to_sequences(input_context)\n# output_tokenized, output_tokenizer = tokenize(output)\n\nprint('Maximum length input sentence: {}'.format(len(max(input_ques_tokenized,key=len))))\nprint('Maximum length input sentence: {}'.format(len(max(input_context_tokenized,key=len))))\nprint('Maximum length output sentence: {}'.format(len(max(output_tokenized,key=len))))\n\n\n# # Check language length\n# input_vocab = len(input_tokenizer.word_index) + 1\n# output_vocab = len(output_tokenizer.word_index) + 1\n# print(\"Input vocabulary is of {} unique words\".format(input_vocab))\n# print(\"Output vocabulary is of {} unique words\".format(output_vocab))","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:10.529192Z","iopub.execute_input":"2022-04-01T21:00:10.529769Z","iopub.status.idle":"2022-04-01T21:00:13.08695Z","shell.execute_reply.started":"2022-04-01T21:00:10.529725Z","shell.execute_reply":"2022-04-01T21:00:13.086081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_ques_input_len = int(len(max(input_ques_tokenized,key=len)))\nmax_context_input_len = int(len(max(input_context_tokenized,key=len)))\nmax_output_len = int(len(max(output_tokenized,key=len)))\n\ninput_ques_pad_sentence = pad_sequences(input_ques_tokenized, max_ques_input_len, padding = \"post\")\ninput_context_pad_sentence = pad_sequences(input_context_tokenized, max_context_input_len, padding = \"post\")\noutput_pad_sentence = pad_sequences(output_tokenized, max_output_len, padding = \"post\")\n\n# Reshape data\ninput_ques_pad_sentence = input_ques_pad_sentence.reshape(*input_ques_pad_sentence.shape, 1)\ninput_context_pad_sentence = input_context_pad_sentence.reshape(*input_context_pad_sentence.shape, 1)\noutput_pad_sentence = output_pad_sentence.reshape(*output_pad_sentence.shape, 1)","metadata":{"id":"qo4q2umpDZAf","execution":{"iopub.status.busy":"2022-04-01T21:00:13.088303Z","iopub.execute_input":"2022-04-01T21:00:13.088589Z","iopub.status.idle":"2022-04-01T21:00:13.9706Z","shell.execute_reply.started":"2022-04-01T21:00:13.088558Z","shell.execute_reply":"2022-04-01T21:00:13.96977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_input_len = int(len(max(input_tokenized,key=len)))\nmax_output_len = int(len(max(output_tokenized,key=len)))\n\ninput_pad_sentence = pad_sequences(input_tokenized, max_input_len, padding = \"post\")\noutput_pad_sentence = pad_sequences(output_tokenized, max_output_len, padding = \"post\")\n\n# Reshape data\ninput_pad_sentence = input_pad_sentence.reshape(*input_pad_sentence.shape, 1)\noutput_pad_sentence = output_pad_sentence.reshape(*output_pad_sentence.shape, 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:13.972004Z","iopub.execute_input":"2022-04-01T21:00:13.972278Z","iopub.status.idle":"2022-04-01T21:00:15.027182Z","shell.execute_reply.started":"2022-04-01T21:00:13.972241Z","shell.execute_reply":"2022-04-01T21:00:15.026354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ques_emb=get_sentence_embeddings(input_ques_data)\ninput_context_emb=get_sentence_embeddings(input_context_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:15.028465Z","iopub.execute_input":"2022-04-01T21:00:15.028718Z","iopub.status.idle":"2022-04-01T21:00:49.451387Z","shell.execute_reply.started":"2022-04-01T21:00:15.028684Z","shell.execute_reply":"2022-04-01T21:00:49.450576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model","metadata":{"id":"WdcEEHOPEZCM"}},{"cell_type":"code","source":"ques_input_sequence = Input(shape=(max_ques_input_len,))\nques_embedding = Embedding(input_dim=input_vocab, output_dim=128,)(ques_input_sequence)\nques_encoder = Bidirectional(LSTM(64, return_sequences=False))(ques_embedding)\nques_r_vec = RepeatVector(max_output_len)(ques_encoder)\na_ques,att_ques=Attention(return_sequences=True)(ques_r_vec)\n\ncontext_input_sequence = Input(shape=(max_context_input_len,))\ncontext_embedding = Embedding(input_dim=input_vocab, output_dim=128,)(context_input_sequence)\ncontext_encoder = Bidirectional(LSTM(64, return_sequences=False))(context_embedding)\ncontext_r_vec = RepeatVector(max_output_len)(context_encoder)\na_context,att_context=Attention(return_sequences=True)(context_r_vec)\n\nsent_ques_input_sequence = Input(shape=(input_ques_emb.shape[1],))\nsent_ques_embedding = Embedding(input_dim=input_vocab, output_dim=128,)(sent_ques_input_sequence)\nsent_ques_encoder = Bidirectional(LSTM(64, return_sequences=False))(sent_ques_embedding)\nsent_ques_r_vec = RepeatVector(max_output_len)(sent_ques_encoder)\na_sent_ques,att_sent_ques=Attention(return_sequences=True)(sent_ques_r_vec)\n\nsent_context_input_sequence = Input(shape=(input_context_emb.shape[1],))\nsent_context_embedding = Embedding(input_dim=input_vocab, output_dim=128,)(sent_context_input_sequence)\nsent_context_encoder = Bidirectional(LSTM(64, return_sequences=False))(sent_context_embedding)\nsent_context_r_vec = RepeatVector(max_output_len)(sent_context_encoder)\na_sent_context,att_sent_context=Attention(return_sequences=True)(sent_context_r_vec)\n\nmerged = Concatenate()([att_ques, att_context,att_sent_ques,att_sent_context])\n\na,att=Attention(return_sequences=True)(merged)\ndecoder = Bidirectional(LSTM(64, return_sequences=True, dropout=0.2))(att)\nlogits = TimeDistributed(Dense(output_vocab))(decoder)","metadata":{"id":"ONRr4W2XENHA","execution":{"iopub.status.busy":"2022-04-01T21:00:49.455059Z","iopub.execute_input":"2022-04-01T21:00:49.45527Z","iopub.status.idle":"2022-04-01T21:00:52.096958Z","shell.execute_reply.started":"2022-04-01T21:00:49.455245Z","shell.execute_reply":"2022-04-01T21:00:52.096072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_dec_model = Model([ques_input_sequence,context_input_sequence,sent_ques_input_sequence,sent_context_input_sequence], Activation('softmax')(logits))\nenc_dec_model.compile(loss=sparse_categorical_crossentropy,\n              optimizer=Adam(1e-3),\n              metrics=['accuracy'])\nenc_dec_model.summary()","metadata":{"id":"XS9GG4VTFdZE","outputId":"7b7c03c3-46b9-4be1-e04b-18811c70af60","execution":{"iopub.status.busy":"2022-04-01T21:00:52.098307Z","iopub.execute_input":"2022-04-01T21:00:52.098604Z","iopub.status.idle":"2022-04-01T21:00:52.134779Z","shell.execute_reply.started":"2022-04-01T21:00:52.098569Z","shell.execute_reply":"2022-04-01T21:00:52.134057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ques_pad_sentence=input_ques_pad_sentence[:len(output_train_data)]\ntrain_input_context_pad_sentence=input_context_pad_sentence[:len(output_train_data)]\n\ntrain_output_pad_sentence=output_pad_sentence[:len(output_train_data)]","metadata":{"id":"jOZ27OsiHaOR","execution":{"iopub.status.busy":"2022-04-01T21:00:52.13614Z","iopub.execute_input":"2022-04-01T21:00:52.136409Z","iopub.status.idle":"2022-04-01T21:00:52.141218Z","shell.execute_reply.started":"2022-04-01T21:00:52.136348Z","shell.execute_reply":"2022-04-01T21:00:52.140297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ques_pad_sentence.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:52.142686Z","iopub.execute_input":"2022-04-01T21:00:52.142944Z","iopub.status.idle":"2022-04-01T21:00:52.153291Z","shell.execute_reply.started":"2022-04-01T21:00:52.142907Z","shell.execute_reply":"2022-04-01T21:00:52.152489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ques_emb=input_ques_emb[:len(output_train_data)]\ntrain_input_context_emb=input_context_emb[:len(output_train_data)]","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:00:52.154713Z","iopub.execute_input":"2022-04-01T21:00:52.15507Z","iopub.status.idle":"2022-04-01T21:00:52.161594Z","shell.execute_reply.started":"2022-04-01T21:00:52.155029Z","shell.execute_reply":"2022-04-01T21:00:52.160673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_results = enc_dec_model.fit([train_input_ques_pad_sentence, train_input_context_pad_sentence,train_input_ques_emb,train_input_context_emb],train_output_pad_sentence, batch_size=30, epochs=100)","metadata":{"id":"mQHi1kLnGRwd","outputId":"6f7d9bd1-b4a2-49da-aee7-fd18e697aa13","execution":{"iopub.status.busy":"2022-04-01T21:00:52.163338Z","iopub.execute_input":"2022-04-01T21:00:52.163597Z","iopub.status.idle":"2022-04-01T21:04:52.667306Z","shell.execute_reply.started":"2022-04-01T21:00:52.163544Z","shell.execute_reply":"2022-04-01T21:04:52.666617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_dec_model.save(\"qa_without_embeddings.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:04:52.668619Z","iopub.execute_input":"2022-04-01T21:04:52.668955Z","iopub.status.idle":"2022-04-01T21:04:54.012847Z","shell.execute_reply.started":"2022-04-01T21:04:52.668915Z","shell.execute_reply":"2022-04-01T21:04:54.012064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_dec_model.save('MyModel_tf',save_format='tf')","metadata":{"execution":{"iopub.status.busy":"2022-04-01T21:04:54.014592Z","iopub.execute_input":"2022-04-01T21:04:54.01486Z","iopub.status.idle":"2022-04-01T21:05:54.101641Z","shell.execute_reply.started":"2022-04-01T21:04:54.014823Z","shell.execute_reply":"2022-04-01T21:05:54.100834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def logits_to_sentence(logits, tokenizer):\n\n#     index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n#     index_to_words[0] = '<empty>' \n\n#     return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n\n# index = len(output_train_data)+5\n# print(\"The Input sentence is: {}\".format(input_data[index]))\n# print(\"The Output sentence is: {}\".format(output_data[index]))\n# print('The predicted sentence is :')\n# print(logits_to_sentence(enc_dec_model.predict(input_pad_sentence[index:index+1])[0], input_tokenizer))","metadata":{"id":"HWow0LxlG0A0","outputId":"8ee34611-d7e1-4d19-fddb-ddadaac96ad1","execution":{"iopub.status.busy":"2022-04-01T21:05:54.109525Z","iopub.execute_input":"2022-04-01T21:05:54.109791Z","iopub.status.idle":"2022-04-01T21:05:54.114403Z","shell.execute_reply.started":"2022-04-01T21:05:54.10976Z","shell.execute_reply":"2022-04-01T21:05:54.113683Z"},"trusted":true},"execution_count":null,"outputs":[]}]}